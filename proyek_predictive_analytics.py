# -*- coding: utf-8 -*-
"""Proyek Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kWx6n-e7DPNGZcVYv_mzAn4Y82YmsMQX

# **Predictive Analytics pada Utrecht Housing Dataset**

Akan dilakukan data loading dari file csv bernama utrecht housing huge dengan url sumber data di https://www.kaggle.com/datasets/ictinstitute/utrecht-housing-dataset?select=utrechthousinghuge.csv.

## **Data Loading**
"""

# Commented out IPython magic to ensure Python compatibility.
# Import Library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

# Memuat Dataset
data = "utrechthousinghuge.csv"
housing = pd.read_csv(data)
housing

"""Output dari kode yang telah dijalankan di atas memberikan informasi sebagai berikut:


*   Terdapat 2000 baris records atau jumlah pengamatan dalam dataset.
*   Terdapat 16 kolom pada dataset ini yaitu: id, zipcode, lot-len, lot-width, lot-area, house-area, garden-size, balcony, x-coor, y-coor, buildyear, bathrooms, taxvalue, retailvalue, energy-eff, dan monument.

## **Exploratory Data Analysis**

### Deskripsi Variabel

Berdasarkan informasi dari url pada Kaggle, variabel-variabel pada Utrecht Housing Dataset adalah sebagai berikut:


*   id: merepresentasikan angka antara 0 dan 100000 yang merupakan tanda pengenal unik untuk setiap rumah.
*   zipcode: merepresentasikan kode pos pada setiap rumah yang sesuai dengan area rumah tersebut.
*   lot-len: merepresentasikan panjang dalam meter dari sebidang tanah tempat rumah dibangun di mana setiap rumah dibangun di atas sebidang tanah persegi.
*   lot-width: merepresentasikan lebar dalam meter dari sebidang tanah tempat rumah dibangun, mulai dari 5.0 hingga 100.0 meter.
*   lot-area: merepresentasikan luas total dari kavling tanah tempat rumah dibangun, dapat dihitung dari lot-len dan lot-width.
*   house-area: merepresentasikan area tinggal rumah dalam meter persegi, 30.0 meter persegi merupakan rumah kecil.
*   garden-size: merepresentasikan ukuran taman dalam meter persegi.
*   balcony: merepresentasikan jumlah balkon yang dimiliki rumah tersebut yang pada umumnya berupa 0, 1, atau 2 balkon.
*   x-coor: merepresentasikan koordinat x yang menggambarkan lokasi rumah yang berada di nilai bilangan bulat antara 2000 dan 3000.
*   y-coor: merepresentasikan koordinat y yang menggambarkan lokasi rumah yang berada di nilai bilangan bulat antara 5000 dan 6000.
*   buildyear: merepresentasikan tahun saat rumah itu dibangun di mana beberapa rumah tertua berasal dari tahun 1100 namun sebagian besar rumah dibangun pada abad ke-20.
*   bathrooms: merepresentasikan jumlah kamar mandi yang dimiliki rumah tersebut yang sebagian besar rumah memiliki satu kamar mandi sementara beberapa rumah memiliki 2 atau 3 kamar mandi.
*   taxvalue: merepresentasikan nilai pajak rumah di mana angkanya berada di antara 50000 dan 1000000 yang merupakan nilai konvervatif.
*   retailvalue: merepresentasikan nilai pasar sebuah rumah di mana angkanya berada di antara 50000 dan 1000000 dengan angka dibulatkan ke 1000 terdekat, serta variabel ini akan dijadikan sebagai fitur target.
*   energy-eff: merepresentasikan kehematan energi pada suatu rumah dengan nilai 1 berarti rumah tersebut hemat energi di mana hal tersebut penting untuk tujuan iklim tertentu.
*   monument: merepresentasikan nilai monumental di mana beberapa rumah di Utrecht terutama rumah-rumah tua masih memiliki nilai tersebut karena memiliki desain arsitektur yang unik.
"""

# Memuat Informasi Dataset
housing.info()

"""Dari output informasi pada dataset dengan fungsi info() dapat terlihat bahwa:


*   Terdapat 5 kolom dengan tipe float, yaitu: lot-len, lot-width, lot-area, house-area, dan garden-size yang merupakan tipe data numerik bilangan desimal.
*   Terdapat 11 kolom dengan tipe int, yaitu: id, zipcode, balcony, x-coor, y-coor, buildyear, bathrooms, taxvalue, retailvalue, energy-eff, dan monument yang merupakan tipe data numerik bilangan bulat dengan salah satu kolom yang bernama retailvalue akan menjadi target fitur pada proyek ini.

Uraian tersebut telah menunjukkan bahwa setiap kolom telah memiliki tipe data yang sesuai sehingga langkah selanjutnya akan dilakukan pengecekan deskripsi statistik data dengan fungsi describe().

Sebelum fungsi descibe(), akan dilakukan penghapusan kolom id dan zipcode terlebih dahulu karena pada kolom id bersifat unik untuk setiap baris dataset serta tidak memiliki informasi prediktif apapun terhadap kolom retailvalue sedangkan pada kolom zipcode memang dapat digunakan untuk mewakili lokasi terhadap prediksi harga rumah tetapi karena dalam bentuk angka mentah maka model ditakutkan salah menangkap hubungan linear padahal itu hanya berupa kode lokasi.


"""

# Drop Kolom id dan zipcode
housing = housing.drop(['id', 'zipcode'], axis=1, errors="ignore")

# Memeriksa Ukuran Data Setelah Drop Kolom
housing.shape

# Memuat Informasi Dataset Setelah Drop Kolom
housing.info()

# Memuat Deskripsi Statistik Data
housing.describe()

"""Fungsi describe() telah memberikan informasi statistik pada masing-masing kolom, antara lain:


*   count adalah jumlah sampel pada data.
*   mean adalah nilai rata-rata.
*   std adalah standar deviasi.
*   min adalah nilai minimum pada setiap kolom.
*   25% adalah kuartil pertama di mana kuartil merupakan nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
*   50% adalah kuartil kedua atau yang biasa disebut sebagai median (nilai tengah).
*   75% adalah kuartil ketiga.
*   max adalah nilai maksimum pada setiap kolom.

### Memeriksa Missing Value

Berdasarkan hasil fungsi describe(), dapat terlihat bahwa setiap kolom variabel tidak memiliki missing value tetapi untuk memastikan maka akan dilakukan pemeriksaan missing value pada setiap kolom variabel kecuali kolom balcony, energy-eff, dan monument karena tidak semua rumah memiliki balcony sedangkan untuk kolom energy-eff dan monument merupakan biner dengan hanya 0 dan 1 di mana nilai 0 menyatakan tidak dan nilai 1 menyatakan iya.
"""

# Memeriksa Missing Value
lot_len = (housing['lot-len'] == 0).sum()
lot_width = (housing['lot-width'] == 0).sum()
lot_area = (housing['lot-area'] == 0).sum()
house_area = (housing['house-area'] == 0).sum()
garden_size = (housing['garden-size'] == 0).sum()
x_coor = (housing['x-coor'] == 0).sum()
y_coor = (housing['y-coor'] == 0).sum()
buildyear = (housing['buildyear'] == 0).sum()
bathrooms = (housing['bathrooms'] == 0).sum()
taxvalue = (housing['taxvalue'] == 0).sum()
retailvalue = (housing['retailvalue'] == 0).sum()

print("Nilai 0 di kolom lot-len ada:", lot_len)
print("Nilai 0 di kolom lot-width ada:", lot_width)
print("Nilai 0 di kolom lot-area ada:", lot_area)
print("Nilai 0 di kolom house-area ada:", house_area)
print("Nilai 0 di kolom garden-size ada:", garden_size)
print("Nilai 0 di kolom x-coor ada:", x_coor)
print("Nilai 0 di kolom y-coor ada:", y_coor)
print("Nilai 0 di kolom buildyear ada:", buildyear)
print("Nilai 0 di kolom bathrooms ada:", bathrooms)
print("Nilai 0 di kolom taxvalue ada:", taxvalue)
print("Nilai 0 di kolom retailvalue ada:", retailvalue)

"""Berdasarkan hasil pemeriksaan missing value di atas, didapatkan bahwa setiap kolom kecuali kolom yang dikecualikan tidak memiliki missing value sehingga tidak perlu melakukan teknik untuk mengatasi missing value.

### Memeriksa Outlier

Akan dilakukan deteksi outliers menggunakan teknik visualisasi data, yaitu boxplot. Selanjutnya akan menangani outliers dengan teknik IQR method. IQR merupakan singkatan dari Inter Quartile Range di mana kuartil dari suatu populasi adalah tiga nilai yang membagi distribusi data menjadi empat sebaran dengan seperempat dari data berada di bawah kuartil pertama (Q1), setengah dari data berada di bawah kuartil kedua (Q2), dan tiga perempat dari data berada di kuartil ketiga (Q3) sehingga dengan demikian interquartile range atau IQR = Q3 - Q1.

Variabel kolom yang akan divisualisasi data dengan boxplot, yaitu: lot-len, lot-width, lot-area, house-area, garden-size, buildyear, taxvalue, retailvalue, x-coor, dan y-coor. Untuk variabel kolom balcony, bathrooms, energy-eff, dan monument tidak dimasukkan karena untuk variabel energy-eff dan monument merupakan biner sehingga tidak perlu dideteksi outliernya sedangkan untuk balcony dan bathrooms berupa bilangan diskrit antara 0 sampai dengan 2 serta antara 1 sampai dengan 3 sehingga tidak perlu dideteksi juga outliernya.
"""

# Kolom lot-len
sns.boxplot(x=housing['lot-len'])

# Kolom lot-width
sns.boxplot(x=housing['lot-width'])

# Kolom lot-area
sns.boxplot(x=housing['lot-area'])

# Kolom house-area
sns.boxplot(x=housing['house-area'])

# Kolom garden-size
sns.boxplot(x=housing['garden-size'])

# Kolom buildyear
sns.boxplot(x=housing['buildyear'])

# Kolom taxvalue
sns.boxplot(x=housing['taxvalue'])

# Kolom retailvalue
sns.boxplot(x=housing['retailvalue'])

# Kolom x-coor
sns.boxplot(x=housing['x-coor'])

# Kolom y-coor
sns.boxplot(x=housing['y-coor'])

"""Selanjutnya akan melakukan penanganan outlier sengan metode IQR di mana menggunakan metode IQR untuk mengidentifikasi outlier yang berada di luar Q1 dan Q3 sehingga nilai apa pun yang berada di luar batas ini dianggap sebagai outlier."""

# Mengambil kolom yang akan digunakan untuk deteksi outlier
outlier_cols = housing.select_dtypes(include="number").columns

# Hitung Q1, Q3 dan IQR
Q1 = housing[outlier_cols].quantile(0.25)
Q3 = housing[outlier_cols].quantile(0.75)
IQR = Q3 - Q1

# Buat filter untuk baris yang TIDAK mengandung outlier
filter_outliers = ~((housing[outlier_cols] < (Q1 - 1.5 * IQR)) | (housing[outlier_cols] > (Q3 + 1.5 * IQR))).any(axis=1)

# Terapkan filter ke seluruh dataset asli
housing = housing[filter_outliers]

# Cek ukuran dataset setelah outlier dihapus
housing.shape

"""Dari proses pemeriksaan dan penanganan outlier yang telah dilakukan, dataset yang telah bersih sekarang memiliki 1961 sampel.

### Univariate Analysis

Melakukan proses analisis data dengan teknik Univariate Exploratory Data Analysis di mana seluruh dataset yang akan dianalisis merupakan numerical features.
"""

# Fitur Numerik Dataset
numerical_features = ['lot-len', 'lot-width', 'lot-area', 'house-area', 'garden-size', 'balcony', 'x-coor', 'y-coor', 'buildyear', 'bathrooms', 'taxvalue', 'retailvalue', 'energy-eff', 'monument']

# Histogram Fitur Numerik
housing.hist(bins=50, figsize=(20,15))
plt.show()

"""Dari histogram fitur numerik, khususnya pada variabel "retailvalue" yang merupakan fitur target (label) pada data. Dari histogram "retailvalue", dapat diperoleh beberapa informasi, seperti:


*   Histogram retailvalue menunjukkan bahwa distribusi mendekati normal, tetapi terdapat sedikit kemiringan ke kanan (right-skewed) yang berarti sebagian besar rumah memiliki nilai jual atau retailvalue pada rentang menengah ke bawah namun terdapat juga beberapa rumah yang bernilai sangat tinggi walaupun sedikit.
*   Setiap peningkatan harga rumah (retailvalue) sebanding dengan penurunan jumlah sampel (frekuensi data) dengan grafik yang mengalami penurunan seiring yang berarti jumlah rumah dengan harga tinggi jauh lebih sedikit dibandingkan rumah dengan harga menengah atau rendah.

### Multivariate Analysis

Akan dilakukan multivariate exploratory data analysis di mana menunjukkan hubungan antara dua atau lebih variabel pada data. Multivariate exploratory data analysis yang menunjukkan hubungan antara dua variabel biasa dapat disebut sebagai bivariate exploratory data analysis. Pada langkah ini, akan dilakukan analisis data pada fitur numerik.

Pada langkah ini, akan melakukan pengamatan hubungan antara fitur numerik dengan menggunakan fungsi pairplot(). Tidak hanya itu, tetapi juga akan mengobservasi korelasi antar fitur numerik dengan fitur target menggunakan fungsi corr().
"""

# Mengamati Hubungan antar Fitur Numerik dengan Fungsi pairplot()
sns.pairplot(housing, diag_kind = "kde")

"""Berdasarkan pola sebaran data grafik pairplot, kolom variabel 'taxvalue' memiliki korelasi yang tinggi dengan fitur "retailvalue", fitur 'house-area' dan 'lot-area' memiliki korelasi sedang, sedangkan fitur 'balcony', 'monument', 'energy-eff', 'bathrooms', dan 'buildyear' memiliki korelasi yang lemah karena sebarannya tidak membentuk pola sehingga akan melakukan evaluasi skor korelasi dengan menggunakan fungsi corr()."""

# Memeriksa Korelasi dengan Heatmap
plt.figure(figsize=(15, 10))
correlation_matrix = housing.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap="coolwarm", linewidths=0.5, )
plt.title("Correlation Matrix Fitur Numerik", size=20)

"""Berdasarkan grafik korelasi di atas, fitur 'house-area', 'taxvalue', dan 'lot-width' memiliki skor korelasi yang besar (di atas 0.7) dengan fitur target "retailvalue". Artinya, fitur "retailvalue" berkorelasi tinggi dengan kedua fitur tersebut. Sementara, fitur 'lot-area' memiliki korelasi sedang (0.5). Lalu, fitur 'lot-len', 'garden-size', 'balcony', 'x-coor', 'y-coor', 'buildyear', 'bathrooms', 'energy-eff', dan 'monument'
memiliki korelasi yang sangat kecil bahkan ada yang hampir tidak berkorelasi sehingga fitur tersebut akan didrop. Namun, karena ada beberapa fitur yang berkorelasi rendah maupun tidak berkorelasi yang masih masuk akal sehingga akan dipertahankan.
"""

# Drop Fitur yang Berkorelasi Rendah maupun Tidak Berkorelasi
housing.drop(['lot-len', 'garden-size', 'balcony', 'x-coor', 'y-coor', 'bathrooms'], inplace=True, axis=1)
housing.head()

"""## **Data Preparation**

Tahapan di mana melakukan proses transformasi data sehingga menjadi bentuk yang lebih cocok untuk proses pemodelan. Pada bagian ini akan dilakukan pembagian dataset dengan fungsi train_test_split dari library sklearn dan standarisasi.

### Train-Test-Split

Pada langkah ini, akan menggunakan proporsi pembagian sebesar 80:20 dengan fungsi train_test_split dari sklearn.
"""

# Pembagian Train-Test-Split
from sklearn.model_selection import train_test_split

X = housing.drop(['retailvalue'], axis=1)
y = housing['retailvalue']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Memeriksa Jumlah Sampel pada Masing-Masing Bagian
print(f"Jumlah sampel pada seluruh dataset: {len(X)}")
print(f"Jumlah sampel pada train dataset: {len(X_train)}")
print(f"Jumlah sampel pada test dataset: {len(X_test)}")

"""### Standarisasi

Melakukan fitur standarisasi pada data latih lalu pada tahap evaluasi akan melakukan standarisasi pada data uji. Standarisasi dengan StandardScaler mengurangkan mean (nilai rata-rata) kemudian membagi dengan standar deviasi untuk menggeser distribusi di mana menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0.
"""

# Melakukan Standarisasi
from sklearn.preprocessing import StandardScaler

features_numerical = ['lot-width', 'lot-area', 'house-area', 'buildyear', 'taxvalue', 'energy-eff', 'monument']
scaler = StandardScaler()
scaler.fit(X_train[features_numerical])
X_train[features_numerical] = scaler.transform(X_train.loc[:, features_numerical])
X_train[features_numerical].head()

# Memeriksa Nilai mean dan standar deviasi Setelah Proses Standarisasi
X_train[features_numerical].describe().round(4)

"""Berdasarkan hasil di atas, setelah dilakukan standarisasi sekarang nilai mean = 0 dan standar deviasi = 1.

## **Model Development**

Tahap pengembangan model di mana akan mengembangkan model machine learning dengan tiga algoritma kemudian akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi yang terbaik. Ketiga algoritma yang akan digunakan adalah K-Nearest Neighbor, Random Forest, dan Boosting Algorithm.
"""

# Menyiapkan DataFrame untuk Analisis Model
models = pd.DataFrame(index=["train_mse", "test_mse"], columns=["KNN", "RF", "Boosting"])

"""### K-Nearest Neighbor"""

# KNN
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

models.loc["train_mse", "knn"] = mean_squared_error(y_pred = knn.predict(X_train), y_true = y_train)

"""### Random Forest"""

# RF
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)

models.loc["train_mse", "rf"] = mean_squared_error(y_pred = rf.predict(X_train), y_true = y_train)

"""### Boosting Algorithm"""

# Boosting
from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=42)
boosting.fit(X_train, y_train)
models.loc["train_mse", "boosting"] = mean_squared_error(y_pred = boosting.predict(X_train), y_true = y_train)

"""## **Evaluasi Model**

Metrik yang akan digunakan pada prediksi harga saat ini adalah MSE atau Mean Squared Error yang menghitung jumlah selisih kuadrat rata-rata nilai sebenarnya dengan nilai prediksi.

Sebelum menghitung nilai MSE dalam model, perlu melakukan proses scaling fitur numerik pada data uji baru melakukan proses scaling pada data latih untuk menghindari kebocoran data. Setelah model selesai dilatih dengan seluruh algoritma, akan melakukan proses scaling terhadap data uji. Hal ini perlu dilakukan agar skala antar data latih dan data uji sama serta dapat melakukan evaluasi.
"""

# Melakukan Scaling Fitur Numerik pada X_test sehingga Memiliki rata-rata = 0 dan varians = 1
X_test.loc[:, features_numerical] = scaler.transform(X_test[features_numerical])

# Membuat Variabel mse yang Berisi DataFrame Nilai mse Data Train dan Test pada Masing-Masing Algoritma
mse = pd.DataFrame(columns=["train", "test"], index=["KNN", "RF", "Boosting"])

# Membuat Dictionary Setiap Algoritma yang Digunakan
model_dict = {"KNN": knn, "RF": rf, "Boosting": boosting}

# Menghitung Mean Squared Error Masing-Masing Algoritma pada Data Train dan Test
for name, model in model_dict.items():
  mse.loc[name, "train"] = mean_squared_error(y_true = y_train, y_pred = model.predict(X_train))/1e6
  mse.loc[name, "test"] = mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))/1e6

# Memanggil mse
mse

# Menampilkan Plot Metrik dengan Bar Chart
fig, ax = plt.subplots()
mse.sort_values(by = "test", ascending = False).plot(kind = "barh", ax = ax, zorder = 3)
ax.grid(zorder=0)

"""Berdasarkan visualisasi plot metrik dengan bar chart, dapat terlihat bahwa model K-Nearest Neighbor (KNN) menampilkan nilai error yang paling kecil sedangkan model dengan algoritma Boosting memiliki error terbesar sehingga model KNN yang akan dipilih sebagai model terbaik untuk melakukan prediksi harga Utrecht housing."""

# Menguji dengan Prediksi Menggunakan Beberapa Harga dari Data Test
prediction = X_test.iloc[:1].copy()
pred_dict = {"y_true": y_test[:1]}
for name, model in model_dict.items():
  pred_dict["prediction_"+name] = model.predict(prediction).round(1)

pd.DataFrame(pred_dict)

"""Berdasarkan hasil pengujian di atas, dapat terlihat bahwa prediksi dengan K-Nearest Neighbor memberikan hasil yang paling mendekati."""